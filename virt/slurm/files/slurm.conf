ClusterName=slurm
ControlMachine=slurm1
Include /etc/slurm/slurm-nodes.conf
Include /etc/slurm/slurm-partitions.conf
Include /etc/slurm/slurm-user.conf
#Include /etc/slurm/slurm-health.conf

TopologyPlugin=topology/tree

SwitchType=switch/none
#TaskPlugin=task/none
TaskPlugin=task/affinity,task/cgroup
MpiDefault=none
ReturnToService=2

# Accounting.
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageHost=slurm1
AccountingStorageUser=slurm
#AccountingStorageEnforce=qos,limits
#AccountingStoragePass=
#AccountingStoragePort=

# Logging
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdLogFile=/var/log/slurm/slurmd.log

StateSaveLocation=/var/spool/slurm
AuthType=auth/munge

# defq (and likely all other partitions) will allow
# oversubscribe. This DefMemPerNode is helpful, otherwise
# a single job will default to max mem per node for the
# cluster if no mem request is made.
DefMemPerNode=100

# allows X-forwarding in interactive jobs. e.g.
#  1. log in to head node with X-forwarding enabled
#  2. # srun --pty --x11 bash -i 
#  3. X applications work from interactive job
PrologFlags=X11
